diag(z.obs)<-NA
for(i in 1:ncol(y)){ #loop thru variables
y.obs<-sort(z.obs[,i])
y.ran<-matrix(0,perm,length(y.obs))
for(j in 1:perm){
t1<-apply(y,2,sample) #permute data matrix
t2<-as.matrix(cor(t1,use='complete.obs'))
diag(t2)<-NA
t3<-sort(t2[,i])
if(length(t3)==length(y.obs)) y.ran[j,]<-t3
}
y.ran.lower<-apply(y.ran,2,quantile,probs=quantiles[1])
y.ran.upper<-apply(y.ran,2,quantile,probs=quantiles[2])
par(new=FALSE)
plot(y.obs,type='l',lwd=2,col='blue',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='Rank order of pairwise correlations',
ylab='Correlation',
main=paste('Redundancy of ',names(y[i]),' vs. random data',sep=''),...)
par(new=TRUE)
plot(y.ran.lower,type='l',lwd=2,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
par(new=TRUE)
plot(y.ran.upper,type='l',lwd=2,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
abline(h=0,col='red',lty=3,lwd=1,...)
legend(x='bottomright',inset=c(.1,.1),legend=c('Actual','Random (95CI)'),
col=c('blue','green'),lty=c(1,1),lwd=c(2,1))
if(!i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru variables
}
else{
z.obs<-sort(as.vector(as.dist(cor(x,use='complete.obs'))))
z.ran<-matrix(0,perm,length(z.obs))
for(i in 1:perm){
t1<-apply(x,2,sample) #permute data matrix
t2<-sort(as.vector(as.dist(cor(t1,use='complete.obs'))))
if(length(t2)==length(z.obs)) z.ran[i,]<-t2
}
z.ran.lower<-apply(z.ran,2,quantile,probs=quantiles[1])
z.ran.upper<-apply(z.ran,2,quantile,probs=quantiles[2])
plot(z.obs,type='l',lwd=2,col='blue',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='Rank order of pairwise correlations',
ylab='Correlation',
main='Redundancy of actual vs. random data',...)
par(new=TRUE)
plot(z.ran.lower,type='l',lwd=1,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
par(new=TRUE)
plot(z.ran.upper,type='l',lwd=1,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
abline(h=0,col='red',lty=3,lwd=1,...)
legend(x='bottomright',inset=c(.1,.1),legend=c('Actual','Random (95CI)'),
col=c('blue','green'),lty=c(1,1),lwd=c(2,1))
}
par(old.par)
}
`replace.missing` <-
function(x,var='',method='median',outfile=''){
if(!var==''){
y1<-subset(x,select=-eval(parse(text=var))) #select all other variables
y2<-subset(x,select=eval(parse(text=var))) #select all specified variables
}
else{
y2<-x #original variables
}
if(method=='mean'){ #for method=mean
for(i in names(y2)){ #loop through selected variables
t<-round(mean(y2[[i]],na.rm=TRUE),3) #compute mean for each variable
y2[is.na(y2[[i]]),i]<-t #assign mean value to missing value
}
}
if(method=='median'){ #for method=median
for(i in names(y2)){ #loop through selected variables
t<-median(y2[[i]],na.rm=TRUE) #compute median for each variable
y2[is.na(y2[[i]]),i]<-t #assign median value to missing value
}
}
if(!var==''){
z<-cbind(y1,y2) #combine deselected and (modified) selected variables
}
else{z<-y2}
if(!outfile==''){ #save outfile
write.table(z,file=paste(outfile,'.csv',sep=''),quote=FALSE,sep=',')
} #end save outfile
return(z)
} #end function
`scatter.plots` <-
function(data,y,x,lowess=TRUE,col.line='red',cex.main=2,...){
oldpar<-par(no.readonly=TRUE)
y<-as.data.frame(subset(data,select=eval(parse(text=y)))) #select y variable
x<-as.data.frame(subset(data,select=eval(parse(text=x)))) #select y variable
#loop thru y variables
for(i in 1:ncol(y)){
#loop thru x variables
for (j in 1:ncol(x)){
#scatter plot
plot(x[,j],y[,i],yaxs='i',xaxs='i',
xlab=names(x[j]),ylab=names(y[i]),
main=paste(names(x[j]),'vs',names(y[i]),sep='  '),
cex.main=cex.main,...)
if(lowess==TRUE){
ok<-is.finite(x[,j]) & is.finite(y[,i])
if(any(ok))	lines(lowess(x[,j][ok],y[,i][ok]),col=col.line)
}
if(!j==ncol(x) | !i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru x variables
} #end loop thru y variables
par(oldpar)
} #end function
`sum.stats` <-
function(x,var='',by='',margin='column',...){
if(!var==''){
y<-subset(x,select=eval(parse(text=var))) #select variables to summarize
}
else{y<-x}
variable<-colnames(y)
sample<-rownames(y)
#statistical functions
nobs<<-function(x,na.rm) length(x)
cv<<-function(x,na.rm) sd(x,na.rm=TRUE)/mean(x,na.rm=TRUE)*100
xeros<<-function(x,na.rm) sum(x==0,na.rm=TRUE)
pct.xeros<<-function(x,na.rm) sum(x==0,na.rm=TRUE)/length(x)*100
nobs.missing<<-function(x,na.rm) sum(is.na(x))
pct.missing<<-function(x,na.rm) sum(is.na(x))/length(x)*100
se<<-function(x,na.rm) sd(x,na.rm=TRUE)/sqrt(length(x)-sum(is.na(x)))
se.ratio<<-function(x,na.rm) se(x)/mean(x,na.rm=TRUE)*100
richness<<-function(x,na.rm) nobs(x)-xeros(x)-nobs.missing(x)
sh.diversity<<-function(x,na.rm) -sum(((x)/sum(x,na.rm=TRUE))*log(((x)/sum(x,na.rm=TRUE))),na.rm=TRUE)
sh.evenness<<-function(x,na.rm) sh.diversity(x)/log(richness(x))
si.diversity<<-function(x,na.rm){
if(richness(x)==0) 0
else 1-sum(((x)/sum(x,na.rm=TRUE))*((x)/sum(x,na.rm=TRUE)),na.rm=TRUE)
}
si.evenness<<-function(x,na.rm) si.diversity(x)/(1-(1/richness(x)))
if(by==''){ #summary table w/o groups
if(margin=='column'){ #summary table by columns
z1<-data.frame(apply(y,2,function(x){ #calculate stats
z1<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sum(x,na.rm=TRUE),
sd(x,na.rm=TRUE),cv(x),xeros(x),pct.xeros(x),nobs.missing(x),
pct.missing(x),se(x),se.ratio(x),richness(x),sh.diversity(x),
sh.evenness(x),si.diversity(x),si.evenness(x))
names(z1)<-c('nobs','min','max','mean',
'median','sum','sd','cv','xeros','pct.xeros',
'nobs.missing','pct.missing','se','se.ratio',
'richness','sh.diversity','sh.evenness',
'si.diversity','si.evenness') #create col names
z1<-round(z1,3) #round elements to 3 decimal places
}))
z2<-data.frame(t(apply(z1,1,function(x){ #calculate stats on stats
z2<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sd(x,na.rm=TRUE),cv(x))
names(z2)<-c('nobs','min','max','mean',
'median','sd','cv') #create row names
z2<-round(z2,3) #round elements to 3 decimal places
})))
z<-list(z1,z2) #create list with col stats and sum stats
names(z)<-c('Column.Summary','Table.Summary')
} #end summary table by columns
else{ #summary table by rows
z1<-data.frame(t(apply(y,1,function(x){ #calculate stats
z1<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sum(x,na.rm=TRUE),
sd(x,na.rm=TRUE),cv(x),xeros(x),pct.xeros(x),nobs.missing(x),
pct.missing(x),se(x),se.ratio(x),richness(x),sh.diversity(x),
sh.evenness(x),si.diversity(x),si.evenness(x))
names(z1)<-c('nobs','min','max','mean',
'median','sum','sd','cv','xeros','pct.xeros',
'nobs.missing','pct.missing','se','se.ratio',
'richness','sh.diversity','sh.evenness',
'si.diversity','si.evenness') #create col names
z1<-round(z1,3) #round elements to 3 decimal places
})))
z2<-data.frame(apply(z1,2,function(x){ #calculate stats on stats
z2<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sd(x,na.rm=TRUE),cv(x))
names(z2)<-c('nobs','min','max','mean',
'median','sd','cv') #create row names
z2<-round(z2,3) #round elements to 3 decimal places
}))
z<-list(z1,z2) #create list with row stats and sum stats
names(z)<-c('Row.Summary','Table.Summary')
} #end summary table by rows
} #end summary table w/o groups
else{ #summary table w/ groups
#	write('',file=paste(outfile,'.csv',sep='')) #empty outfile if it exists
fns<-c('nobs','min','max','mean',
'median','sum','sd','cv','xeros','pct.xeros',
'nobs.missing','pct.missing','se','se.ratio',
'richness','sh.diversity','sh.evenness',
'si.diversity','si.evenness') #create names vector
n<-by.names(x,by) #create by variable
for(i in 1:length(fns)){ #loop thru by groups
cat(t<-paste(strtrim(paste('--',fns[i],paste(rep('-',80),collapse='')),80),'\n')) #create line break
q<-list(n[,2]) #create a list of group names
names(q)<-names(n)[2] #assign by name to q
z1<-aggregate(y,q,fns[i],na.rm=TRUE) #calculate stats
zz1<-round(z1[,2:ncol(z1)],3) #round stats to 3 decimal places
g<-z1[,1,,drop=FALSE] #select group variable
z1<-cbind(g,zz1) #bind group variable with selected variables
z2<-data.frame(t(apply(z1[,-1],1,function(x){ #calculate stats on stats
z2<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sd(x,na.rm=TRUE),cv(x))
names(z2)<-c('nobs','min','max','mean',
'median','sd','cv') #create row names
z2<-round(z2,3) #round elements to 3 decimal places
})))
z<-cbind(z1,z2) #bind col stats with summary stats
print(z) #print to console
} #end loop thru groups
} #end summary table w/ groups
return(z)
} #end function
`tau` <-
function(y,prior){
z<-matrix(0,nrow(y),ncol(y)) #create blank matrix
N<-sum(y)
ccr<-sum(diag(y))
n<-apply(y,1,sum)
num<-ccr-sum(prior*n)
den<-N-sum(prior*n)
tau<-num/den
tau[tau<0]<-0
return(tau)
}
`uv.outliers` <-
function(x,id,var,by=NULL,outfile=NULL,sd.limit=3,digits=3){
#sd outliers w/o groups
if(is.null(by)){
y1<-as.data.frame(subset(x,select=eval(parse(text=id)))) #select plot.id variables
y2<-as.data.frame(subset(x,select=eval(parse(text=var)))) #select variables to standardize
t1<-scale(y2) #calculate sd's
t2<-abs(t1)>=sd.limit
row.vector<-apply(t2,1,FUN='any',na.rm=TRUE)#select rows with extremes
col.vector<-apply(t2,2,FUN='any',na.rm=TRUE)#select cols with extremes
if(sum(row.vector)>0){
t3<-t1[row.vector,col.vector,drop=FALSE]
t3[abs(t3)<sd.limit]<-NA
t3<-round(t3,digits)
t4<-as.data.frame(y1[row.vector,,drop=FALSE])
z<-cbind(t4,t3)
if(!is.null(outfile)){ #write table to outfile
write.table(z,file=paste(outfile,'.csv',sep=''),row.names=FALSE,quote=FALSE,sep=',')
} #end save outfile
}
else stop('No outliers exist')
} #end sd outliers w/o groups
#sd outliers w/ groups
else{
if(!is.null(outfile)) write('',file=outfile) #empty outfile if it exists
n<-by.names(x,by) #create by variable
y<-cbind(n,x)
m<-levels(n[,2]) #create object with group levels
z<-vector('list',length(m))	#create list object for output
names(z)<-m #assign names to list components
for(i in 1:length(m)){ #loop thru by groups
t0<-y[n[,2]==m[i],,drop=FALSE] #select records within group
y1<-as.data.frame(subset(t0,select=eval(parse(text=id)))) #select plot.id variables
y2<-as.data.frame(subset(t0,select=eval(parse(text=var)))) #select variables to standardize
t1<-scale(y2) #calculate sd's
t2<-abs(t1)>=sd.limit
row.vector<-apply(t2,1,FUN='any',na.rm=TRUE)#select rows with extremes
col.vector<-apply(t2,2,FUN='any',na.rm=TRUE)#select cols with extremes
if(sum(row.vector)>0){
t3<-t1[row.vector,col.vector,drop=FALSE]
t3[abs(t3)<sd.limit]<-NA
t3<-round(t3,digits)
t4<-as.data.frame(y1[row.vector,,drop=FALSE])
z[[i]]<-cbind(t4,t3)
if(!is.null(outfile)){ #write table to outfile
write(m[i],file=paste(outfile,'.csv',sep=''),append=TRUE)
write.table(z,file=paste(outfile,'.csv',sep=''),quote=FALSE,append=TRUE,sep=',')
} #end save outfile
}
else z[[i]]<-NULL
} #end loop thru groups
} #end sd outliers w/groups
return(z)
} #end function
`uv.plots` <-
function(x,var=NULL,col.fill='blue',col.point='black',
col.line='red',...){
oldpar<-par(no.readonly=TRUE)
if(!is.null(var)){
y<-subset(x,select=eval(parse(text=var))) #select variables to summarize
y<-as.data.frame(y)
}
else{y<-as.data.frame(x)} #graphics settings
#layout plot
layout(matrix(c(1,1,2,3,4,5),
nrow=3,ncol=2,byrow=TRUE),
heights=c(.1,.45,.45),widths=c(.5,.5))
par(mar=c(1,1,1,1))
#loop thru variables
for(i in 1:ncol(y)){
#plot title
plot.new()
text(.5,.5,labels=names(y[i]),
font=2,cex=3,xpd=TRUE)
#histogram (upper left panel)
par(mar=c(5,5,4,2))
hist(y[[i]],prob=TRUE,col=col.fill,
xaxs='i',yaxs='i',xlab=names(y[i]),
main='Histogram',...)
lines(density(y[[i]]))
#box-and-whisker plot (upper right panel)
par(mar=c(5,5,4,2))
boxplot(y[i],col=col.fill,ylab=names(y[i]),
main='Box-and-Whisker Plot',...)
#empirical cumulative distribution function plot (lower left panel)
par(mar=c(5,5,4,2))
plot(sort(y[[i]]),type='o',col=col.point,yaxs='i',xaxs='i',
xlab='Cumulative Number of Plots',ylab=names(y[i]),
main='ECDF Plot',...)
#normal quantile-quantile plot (lower right panel)
par(mar=c(5,5,4,2))
qqnorm(y[,i],datax=TRUE,col=col.point,
main='Normal Q-Q Plot',...)
y.IQR<-IQR(y[,i],na.rm=TRUE)
if(y.IQR>0)	qqline(y[,i],datax=TRUE,col=col.line,...)
par(mar=c(1,1,1,1))
if(!i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru variables
par(oldpar)
} #end function
###################################################################################################
###################################################################################################
#STEP #1: ADMINISTRATIVE TASKS
#Reset functions
#rm(list=ls())#do not run this function b/c it will erase biostats script
dev.off()
#Libraries
library(Hmisc)
library(PerformanceAnalytics)
library(vegan)
library(pastecs)
library(simba)
library(fields)#for set.panel()
library(labdsv)#Brooke's recommendation
install.packages('pastecs')
install.packages('simba')
library(pastecs)
library(simba)
#Plot-level biomass data. This data has been modified so that vine species are consistent
#across all sites and outlier plots located in uncharacteristics areas of sites (wetlands or meadows)
#have been removed.
plotBiomass <- read.table(
"C:/usfs_sef_data_output/sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOulierX_2014-05-05_15.00.18.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
plotBiomass <- read.table(
"C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/LongleafCommunityEcology/Inputs/sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOulierX_2014-05-05_15.00.18.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
plotBiomass <- read.table(
"C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/LongleafCommunityEcology/Inputs/sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOulierX_2014-05-05_15.00.18.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
plotBiomass <- read.table(
"C:/Users/jcronan/Documents/GitHub/LongleafCommunityEcology/Inputs/sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOulierX_2014-05-05_15.00.18.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
getwd()
setwd("C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/LongleafCommunityEcology/Inputs/")
getwd()
plotBiomass <- read.table("sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOulierX_2014-05-05_15.00.18.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
plotBiomass <- read.table("sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOulierX_2014-05-05_15.00.18.csv")
plotBiomass <- read.csv("sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOulierX_2014-05-05_15.00.18.csv")
getwd()
list.files()
plotBiomass <- read.table(
"C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/LongleafCommunityEcology/Inputs/sef_Ecology_BiomassPlotMatrix_Ep1_OriginalOutlierX_2014-05-05_15.00.18.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
#########################################################
#2B The steps below create a more appropriate dataset by combining some categories.
#Combine like categories
#Dead forb and live forb > these are being combined because some sites were sampled in
#winter and some in summer so live or dead forb loadings are an indication of season
#rather then site differences.
forb <- plotBiomass$live.forb + plotBiomass$dead.forb
dead.woody <- plotBiomass$dead.shrub + plotBiomass$dead.tree + plotBiomass$dead.palmetto
palmetto <- plotBiomass$live.palmetto
plotBiomass2 <- plotBiomass[,!colnames(plotBiomass) %in% c("live.forb", "dead.forb",
"dead.shrub", "dead.tree",
"live.palmetto",
"dead.palmetto")]
plotBiomass3 <- data.frame(plotBiomass2, forb = forb, palmetto = palmetto)
siteBiomass <- summarize(X = plotBiomass3[,3:length(plotBiomass3[1,])], by = plotBiomass3$siteName,
colMeans, stat.name = colnames(plotBiomass3)[3])
colnames(siteBiomass)[1] <- "siteName"
siteBiomass2 <- siteBiomass[,2:(length(siteBiomass[1,]))]
rownames(siteBiomass2) <- siteBiomass[,1]
plotBiomassLogTrans <- data.trans(plotBiomass3[,3:length(plotBiomass3[1,])], method = 'log',
plot = F)
siteBiomassLogTrans <- summarize(X = plotBiomassLogTrans, by = plotBiomass3$siteName, colMeans,
stat.name = colnames(plotBiomass3)[3])
colnames(siteBiomassLogTrans)[1] <- "siteName"
#Remove site names from matrix columns and assign as row names.
#All biomass >> LOG-TRANSFORMED
siteBiomassLogTrans2 <- siteBiomassLogTrans[,2:(length(siteBiomassLogTrans[1,]))]
rownames(siteBiomassLogTrans2) <- siteBiomassLogTrans[,1]
plotCover <- read.table(
"C:/usfs_sef_data_output/sef_Ecology_CoverPlotMatrix_Ep1_OriginalOulierX_2014-10-15_10.32.12.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
plotCover <- read.table(
"C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/LongleafCommunityEcology/Inputs/sef_Ecology_CoverPlotMatrix_Ep1_OriginalOutlierX_2014-10-15_10.32.12.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
plotCover <- read.table(
"C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/LongleafCommunityEcology/Inputs/sef_Ecology_CoverPlotMatrix_Ep1_OriginalOutlierX_2014-08-21_17.24.49.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
plotCover2 <- plotCover[,!colnames(plotCover) %in% c("litter", "bare.soil")]
forb <- plotCover2$live.forb + plotCover2$dead.forb
dead.woody <- plotCover2$dead.shrub + plotCover2$dead.tree + plotCover2$dead.palmetto
palmetto <- plotCover2$live.palmetto
plotCover3 <- plotCover2[,!colnames(plotCover2) %in% c("live.forb", "dead.forb", "live.palmetto",
"dead.palmetto", "dead.shrub", "dead.tree")]
plotCover4 <- data.frame(plotCover3, forb = forb, palmetto = palmetto)#did not add dead.woody
siteCover <- summarize(X = plotCover4[,3:length(plotCover4[1,])], by = plotCover4$siteName,
colMeans, stat.name = colnames(plotCover4)[3])
colnames(siteCover)[1] <- "siteName"
siteCover2 <- siteCover[,2:(length(siteCover[1,]))]
rownames(siteCover2) <- siteCover[,1]
siteEnv <- read.table(
"C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/LongleafCommunityEcology/Inputs/2014.03.13_EnvironmentalMatrix.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE,
stringsAsFactors = F)
siteEnv2 <- siteEnv[,2:(length(siteEnv[1,]))]
rownames(siteEnv2) <- siteEnv[,1]
siteEnv3 <- siteEnv2[,-c(12,13)]
ro <- data.frame(siteNo = 1:length(rownames(siteEnv3)), siteName = I(rownames(siteEnv3)))
ro2 <- ro[order(ro[,2]),]
#Untranformed biomass data
siteBiomass3 <- data.frame(so = ro2[,1], siteBiomass2)
siteBiomass4 <- siteBiomass3[order(siteBiomass3$so),]
siteBiomass5 <- siteBiomass4[,!colnames(siteBiomass4) %in% c("so")]
#Log-tranformed biomass data
siteBiomassLogTrans3 <- data.frame(so = ro2[,1], siteBiomassLogTrans2)
siteBiomassLogTrans4 <- siteBiomassLogTrans3[order(siteBiomassLogTrans3$so),]
siteBiomassLogTrans5 <- siteBiomassLogTrans4[,!colnames(siteBiomassLogTrans4) %in% c("so")]
biomassOrig <- drop.var(siteBiomass5, min.fo = 1)
biomassLog <- drop.var(siteBiomassLogTrans5, min.fo = 1)
coverOrig <- drop.var(siteCover2, min.fo = 1)
rownames(biomassOrig)
re <- c(1,2,2,2,1,1,2,1,2,1,2,2,2,1,1,2,1,2,1,1,1,2)
#Split datasets in two by region
#For biomass (untranformed)
bor1 <- biomassOrig[re == 1,]
bor2 <- biomassOrig[re == 2,]
#For biomass (log-tranformed)
blr1 <- biomassLog[re == 1,]
blr2 <- biomassLog[re == 2,]
#For cover (untranformed)
cor1 <- coverOrig[re == 1,]
cor2 <- coverOrig[re == 2,]
round(stat.desc(biomassOrig),2)
foa.plots(biomassOrig)
foa.plots(biomassOrig)
foa.plots(biomassOrig)
bo <- drop.var(biomassOrig, min.po=50)
bl <- drop.var(biomassLog, min.po=50)
bore1 <- drop.var(bor1, min.po=80)
bore2 <- drop.var(bor2, min.po=80)
blre1 <- drop.var(blr1, min.po=80)
blre2 <- drop.var(blr2, min.po=80)
length(biomassOrig[1,])#
length(bo[1,])#
length(biomassLog[1,])#
length(bl[1,])
length(bor1[1,])#
length(bore1[1,])
#39 to 14 variables (25 drops)
length(bor2[1,])#
length(bore2[1,])
#39 to 15 variables (24 drops)
length(blr1[1,])#
length(blre1[1,])
#39 to 14 variables (25 drops)
length(blr2[1,])#
length(blre2[1,])
#39 to 15 variables (24 drops)
str(bo)#22 obs and 13 variables
str(bl)#22 obs and 13 variables
#Convert data.frame to a matrix (needed for uv.plots)
#All
bo2 <- data.matrix(frame = bo, rownames.force = NA)
bl2 <- data.matrix(frame = bl, rownames.force = NA)
#Original (E)glin and (A)palachicola
boE <- data.matrix(frame = bore1, rownames.force = NA)
boA <- data.matrix(frame = bore2, rownames.force = NA)
blE <- data.matrix(frame = blre1, rownames.force = NA)
blA <- data.matrix(frame = blre2, rownames.force = NA)
uv.plots(bo2)
uv.plots(bl2)
uv.plots(boE)
uv.plots(boA)
length(bo2[bo2 == 0])/(length(bo2[1,])*length(bo2[,1]))
length(bl2[bl2 == 0])/(length(bl2[1,])*length(bl2[,1]))
length(boE[boE == 0])/(length(boE[1,])*length(boE[,1]))
length(boA[boA == 0])/(length(boA[1,])*length(boA[,1]))
chart.Correlation(bo2, method = "pearson")
